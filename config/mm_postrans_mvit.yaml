seed_everything: 43
stage: train
logger:
  project: thesis_multimodal

trainer: 
  num_nodes: 1
  devices: 1
  overfit_batches: false
  check_val_every_n_epoch: 1
  accumulate_grad_batches: 2
  max_epochs: 50
  max_steps: -1
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  log_every_n_steps: 50
  accelerator: "gpu"
  precision: 32
  num_sanity_val_steps: 1

data:
  name: LitResampledHblDataset
  params:
    meta_path: "/nfs/home/rhotertj/datasets/hbl/"
    idx_mapping_train: "/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_train.jsonl"
    idx_mapping_val: "/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_val.jsonl"
    idx_mapping_test: "/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_test.jsonl"
    seq_len: 16
    sampling_rate: 2
    load_frames: true
    batch_size: 16
    epsilon : 7
    mix_video: true
    position_format: "flattened"
    relative_positions: false
  transforms:
    - name: vt.FrameSequenceToTensor
    - name: vt.RandomHorizontalFlipVideo
      params:
        p: 0.5
    - name: vt.TimeFirst
    - name: t.ColorJitter
      params:
        brightness: 0.2
        hue: 0.2
        contrast: 0.2
        saturation: 0.2
    # - name: ptvt.RandAugment
    #   params:
    #     num_layers: 3
    #     prob: 0.5
    #     magnitude: 5
    - name: vt.ChannelFirst
    - name: t.Resize
      params:
        size: [224, 224]

model:
  name: MultiModalModel
  params:
    video_model_name: make_kinetics_mvit
    video_model_params:
      pretrained_path: models/mvit_b_16x4.pt
    video_model_ckpt: /nfs/home/rhotertj/Code/thesis/experiments/mvit/train/blooming-hill-271/epoch=6-val_acc=0.85.ckpt
    graph_model_name: PositionTransformer
    graph_model_params:
      dim_in: 49
      dim_h: 256
      input_operation: "linear"
      num_heads: 8
    graph_model_ckpt: /nfs/home/rhotertj/Code/thesis/experiments/posT/train/robust-frog-186/epoch=25-val_acc=0.61.ckpt
    train_head_only: False
    head_type: twin

lit_model:
  name: LitModel

loss_func: twin_head_loss

optimizer:
  name: SGD
  params:
    lr: 0.003
    momentum: 0.9
    weight_decay: 1e-4

scheduler:
  name: CosineAnnealingLR

num_classes: 3
checkpoint: null
save_config: true
log_proportions: true

callbacks:
  - name: ModelCheckpoint
    params:
      every_n_epochs: 1
      dirpath: experiments/mvit/train
      filename: "{epoch}-{val/acc:.2f}"
      monitor: "val/acc"
      mode: max
      auto_insert_metric_name: False
      save_top_k: 2
      save_on_train_epoch_end: false # save end of val
  - name: EarlyStopping
    params:
      monitor: "val/acc"
      patience: 3
      mode: max
      check_on_train_epoch_end: True