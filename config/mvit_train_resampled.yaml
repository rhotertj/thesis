seed_everything: 43
stage: train
logger:
  project: thesis_mvit
trainer: # logger extra
  num_nodes: 1
  devices: 1
  overfit_batches: false # change int of n batches to debug with n batches
  check_val_every_n_epoch: 1
  accumulate_grad_batches: 2
  max_epochs: 50
  max_steps: -1
  max_time: null
  limit_train_batches: null # set fraction of training data
  limit_val_batches: null
  limit_test_batches: null
  log_every_n_steps: 50
  accelerator: "gpu"
  precision: 32
  num_sanity_val_steps: 1
dataset: LitResampledHblDataset
data:
  meta_path: "/nfs/home/rhotertj/datasets/hbl/meta3d.csv"
  idx_mapping_train: "/nfs/home/rhotertj/datasets/hbl/meta3d_16_2_nooverlap_train_balanced.jsonl"
  idx_mapping_val: "/nfs/home/rhotertj/datasets/hbl/meta3d_16_2_nooverlap_val_balanced.jsonl"
  idx_mapping_test: "/nfs/home/rhotertj/datasets/hbl/meta3d_16_2_nooverlap_val_balanced.jsonl"
  seq_len: 16
  sampling_rate: 2
  load_frames: true
  batch_size: 16
model:
  pretrained_path: "models/mvit_b_16x4.pt"
  learning_rate: 0.03
  momentum: 0.9
  weight_decay: 1e-4
num_classes: 3
checkpoint: null
callbacks:
  checkpointing:
    every_n: 1
    dir: experiments/mvit/train
save_config: true
