{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # root of repo\n",
    "sys.path.append(\"../src/\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import Counter, defaultdict\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from src.data.datasets import MultiModalHblDataset, ResampledHblDataset\n",
    "from src.data.labels import LabelDecoder\n",
    "from src.utils import array2gif, draw_trajectory\n",
    "from src.metrics import postprocess_predictions, average_mAP, postprocess_peaks_only\n",
    "import torchvision\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision.transforms as t\n",
    "import multimodal_transforms as mmt\n",
    "import pytorchvideo.transforms as ptvt\n",
    "from lit_data import collate_function_builder\n",
    "\n",
    "from utils import * # debug import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot class occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"dataset_train_sql=16_sr=2_nooverlap.jsonl\", lines=True)\n",
    "df.sample(5)\n",
    "# TODO np diff over idx with actions at sr=1 gives us frame distance between actions, bar chart for intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Get frames and matches\n",
    "data = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_valid.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_val.jsonl\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False,\n",
    "    label_mapping=LabelDecoder(3)\n",
    ")\n",
    "ld = LabelDecoder(3)\n",
    "shot_frames = []\n",
    "pass_frames = []\n",
    "for df in data.event_dfs:\n",
    "    frames = df.index.to_numpy()\n",
    "    label = df.labels.apply(lambda x : ld(x)).to_numpy()\n",
    "    shot_frames.append(frames[label == 2])\n",
    "    pass_frames.append(frames[label == 1])\n",
    "shot_frames = np.concatenate(shot_frames)\n",
    "pass_frames = np.concatenate(pass_frames)\n",
    "print(len(shot_frames), len(pass_frames))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging idx -> Frame index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 4\n",
    "hql = sql // 2\n",
    "rate = 2\n",
    "sr = sql * rate\n",
    "hr = hql * rate\n",
    "kernel = np.ones(sr)\n",
    "\n",
    "availables = [True, True, True, True, True, True, True, True, True, True, True, True, True, False, False]\n",
    "pos = np.arange(len(availables))\n",
    "\n",
    "cv = np.convolve(availables, kernel)\n",
    "print(f\"{cv}\")\n",
    "idxs = np.where(cv == sr)[0] - (sr - 1) # subtract filter length - 1\n",
    "print(\"idx for valid sequences:\", idxs)\n",
    "\n",
    "q_idx = 0\n",
    "f_idx = idxs[q_idx] + hr\n",
    "sequence = pos[f_idx - hr : f_idx + hr : rate]\n",
    "print(f\"Idx for sequence {q_idx}: {sequence}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_valid.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_val.jsonl\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=True,\n",
    "    label_mapping=LabelDecoder(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../img/classes\", exist_ok=True)\n",
    "n_per_class = 3\n",
    "shots = list(range(0, 9))\n",
    "passes = ['A', 'B', 'C', 'D', 'E', 'X', 'O']\n",
    "df = dataset.idx_to_frame_number\n",
    "for s,p in itertools.product(shots, passes):\n",
    "    events = df[(df['shot'] == s) & (df['pass'] == p)]\n",
    "    if len(events) > 0:\n",
    "        events = events.sample(n_per_class)\n",
    "        for i, (idx, event) in enumerate(events.iterrows()):\n",
    "            instance = dataset.__getitem__(idx)\n",
    "            fname = f\"../img/classes/{s}_{p}_{i}\"\n",
    "            array2gif(instance[\"frames\"], fname + \".gif\", 10)\n",
    "            f = draw_trajectory(instance[\"positions\"])\n",
    "            plt.savefig(fname + \".png\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 1\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True\n",
    ")\n",
    "print(len(dataset_img))\n",
    "n = 0\n",
    "means = np.zeros((len(dataset_img) + sql, 3))\n",
    "stds = np.zeros((len(dataset_img) + sql, 3))\n",
    "\n",
    "for i in tqdm(range(0, len(dataset_img), sql)):\n",
    "    frames = torch.tensor(dataset_img[i][\"frames\"]) / 255\n",
    "\n",
    "    for j, frame in enumerate(frames):\n",
    "        mean, std = frame.mean([1,2]), frame.std([1,2])\n",
    "        means[i+j] = mean\n",
    "        stds[i+j] = std\n",
    "\n",
    "        n+=1\n",
    "print(n)\n",
    "print(means.shape)\n",
    "# Maybe we want to calculate this per match instead of over the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"means.npy\", means)\n",
    "np.save(\"std.npy\", stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.mean(0), stds.mean(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = dataset_img[11345]\n",
    "draw_trajectory(instance[\"positions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poscon = instance[\"positions\"].mirror_again(horizontal=True, vertical=False)\n",
    "draw_trajectory(poscon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transforms and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms_jitter = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.ColorJitter(brightness=0.2, hue=.2, contrast=0.2, saturation=0.2),\n",
    "            mmt.ChannelFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            ])\n",
    "\n",
    "transforms_randaugment = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            #ptvt.RandAugment(num_layers=3, prob=0.5, magnitude=5),\n",
    "            mmt.ChannelFirst(),\n",
    "            ])\n",
    "\n",
    "transforms_translate = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            mmt.Translate()\n",
    "    ])\n",
    "\n",
    "transforms_raw = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "    ])\n",
    "\n",
    "transforms_full = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.RandomHorizontalFlipVideo(p=0.5),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.ColorJitter(brightness=0.2, hue=.2, contrast=0.2, saturation=0.2),\n",
    "            #ptvt.RandAugment(num_layers=3, prob=0.5, magnitude=5),\n",
    "            mmt.ChannelFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            ])\n",
    "dataset_img = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_train.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/upsampled/True/meta30_train.jsonl\",\n",
    "    label_mapping=LabelDecoder(3),\n",
    "    load_frames=True,\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    transforms=transforms_raw\n",
    ")\n",
    "\n",
    "collate_mixvideo = collate_function_builder(epsilon=7, load_frames=True, mix_video=ptvt.MixVideo(num_classes=3, cutmix_alpha=0.8, cutmix_prob=0))\n",
    "collate_fn = collate_function_builder(epsilon=7, load_frames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_instances = []\n",
    "jitter_instances = []\n",
    "randaug_instances = []\n",
    "combined_instances = []\n",
    "translate_instances = []\n",
    "idxs = [13456,23574,98533,64378,22546,324567,243343,9632] #random\n",
    "for i in range(8):\n",
    "    dataset_img.transforms = transforms_raw\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    raw_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_translate\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    translate_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_jitter\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    jitter_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_randaugment\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    randaug_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_full\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    combined_instances.append(instance)\n",
    "dataset_img.transforms = transforms_raw\n",
    "\n",
    "raw_batch = collate_fn(raw_instances)\n",
    "mix_batch = collate_mixvideo(raw_instances)\n",
    "jitter_batch = collate_fn(jitter_instances)\n",
    "translate_batch = collate_fn(translate_instances)\n",
    "combined_batch = collate_mixvideo(combined_instances)\n",
    "\n",
    "raw_pos = None\n",
    "for i in range(8):\n",
    "    for name, batch in zip([\"raw\", \"mixvideo\", \"jitter\", \"translate\", \"combined\"], [raw_batch, mix_batch, jitter_batch, translate_batch, combined_batch]):\n",
    "        frames = batch[\"frames\"][i].mul(255).to(torch.uint8).numpy()\n",
    "        array2gif(frames, f\"../img/transforms/{name}_transforms_{i}.gif\", 10)\n",
    "        if name == \"raw\":\n",
    "            raw_pos = batch[\"positions\"]\n",
    "        if name == \"translate\":\n",
    "            print(raw_pos.ndata[\"positions\"][0], batch[\"positions\"].ndata[\"positions\"][0])\n",
    "        if name in (\"translate\", \"raw\"):\n",
    "            q_idx = batch[\"query_idx\"][i].item()\n",
    "            pos = dataset_img[q_idx][\"positions\"]\n",
    "            fig = draw_trajectory(pos)\n",
    "            plt.savefig(f\"../img/transforms/{name}_transforms_positions_{i}.png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_match = 2\n",
    "mult = 100\n",
    "for i, border in tqdm(enumerate(dataset_img.index_tracker[:-1])):\n",
    "    for j in range(n_per_match):\n",
    "        instance = dataset_img[border + (j+2)*mult]\n",
    "        mn = dataset_img.meta_df.iloc[instance[\"match_number\"]][\"match_id\"].split(\":\")[-1]\n",
    "        os.makedirs(f\"/nfs/home/rhotertj/Code/thesis/img/matches/{mn}\",exist_ok=True)\n",
    "        fname = f\"../img/matches/{mn}/{(j+8)*mult}\"\n",
    "        array2gif(instance[\"frames\"], fname + \".gif\", 10)\n",
    "        f = draw_trajectory(instance[\"positions\"])\n",
    "        plt.savefig(fname + \".png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing average MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res_name = \"/nfs/home/rhotertj/Code/thesis/dataset/analysis/blooming-hill-271/val_results.pkl\"\n",
    "# val_res_name = \"/nfs/home/rhotertj/Code/thesis/dataset/analysis/copper-bush-8/val_results.pkl\"\n",
    "with open(val_res_name, \"rb\") as f:\n",
    "    val_results = pkl.load(f)\n",
    "\n",
    "df = pd.DataFrame(val_results)\n",
    "confidences = np.concatenate(df.confidences.to_numpy())\n",
    "frame_numbers = df.frame_idx.to_numpy()\n",
    "match_numbers = df.match_number.to_numpy()\n",
    "label_idx = df.label_idx.to_numpy()\n",
    "labels = df.label.to_numpy()\n",
    "label_offsets = df.label_offset.to_numpy()\n",
    "\n",
    "# boost frame numbers per game\n",
    "max_frame_magnitude = len(str(frame_numbers.max()))\n",
    "frame_offset = 10**(max_frame_magnitude + 1)\n",
    "frame_numbers = frame_numbers + (frame_offset * match_numbers)\n",
    "\n",
    "correct_order = np.argsort(frame_numbers)\n",
    "reordered_frames = frame_numbers[correct_order]\n",
    "confidences = confidences[correct_order]\n",
    "\n",
    "# labelidx solution\n",
    "gt_labels_ll = []\n",
    "gt_anchors_ll = []\n",
    "offset_ll = []\n",
    "for i, l_idx in enumerate(label_idx):\n",
    "    if l_idx == -1:\n",
    "        continue\n",
    "    f = frame_offset * match_numbers[i] + l_idx\n",
    "    if f in gt_anchors_ll:\n",
    "        continue\n",
    "    l = labels[i]\n",
    "    gt_labels_ll.append(l)\n",
    "    gt_anchors_ll.append(f)\n",
    "    offset_ll.append(label_offsets[i])\n",
    "\n",
    "gt_anchors_ll = np.array(gt_anchors_ll)\n",
    "gt_labels_ll = np.array(gt_labels_ll)\n",
    "\n",
    "correct_order = np.argsort(gt_anchors_ll)\n",
    "gt_anchors_ll = gt_anchors_ll[correct_order]\n",
    "gt_labels_ll = gt_labels_ll[correct_order]\n",
    "gt_anchors = gt_anchors_ll\n",
    "gt_labels = gt_labels_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plots and helpers\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "lm = LabelDecoder(3)\n",
    "int2class = lambda i: lm.get_classnames()[i]\n",
    "class2int = lambda c: lm.get_classnames().index(c)\n",
    "\n",
    "# put predictions into \n",
    "pred_list = []\n",
    "for (f, cs) in zip(reordered_frames, confidences):\n",
    "    for i, c in enumerate(cs):\n",
    "        plot_preds = {}\n",
    "        plot_preds[\"frame\"] = f\n",
    "        plot_preds[\"type\"] = int2class(i)\n",
    "        plot_preds[\"confidence\"] = c\n",
    "        pred_list.append(plot_preds)\n",
    "\n",
    "pred_df = pd.DataFrame(pred_list)\n",
    "pred_df.sort_values(by=\"frame\", inplace=True)\n",
    "\n",
    "start_frame = 30000 # 5000 - 8000\n",
    "end_frame = 308000\n",
    "palette = sns.color_palette(\"husl\")\n",
    "class_palette = {c: color for c, color in zip(lm.get_classnames(), palette[:3])}\n",
    "plot_data = pred_df[(pred_df[\"frame\"] > start_frame) & (pred_df[\"frame\"] < end_frame)]\n",
    "sns.scatterplot(data=plot_data, x=\"frame\", y=\"confidence\", hue=\"type\", palette=class_palette, ax=ax)\n",
    "\n",
    "# plot ground truth\n",
    "plotted_frames_in_gt = np.where((gt_anchors < end_frame) & (gt_anchors > start_frame))[0]\n",
    "for c, f in zip(gt_labels[plotted_frames_in_gt], gt_anchors[plotted_frames_in_gt]):\n",
    "    if c != 0: # fix div by 2 == 0 bug later\n",
    "        ax.axvline(x=f, color=palette[c], linestyle=\"-\")\n",
    "        pass\n",
    "\n",
    "# do post-processing\n",
    "\n",
    "anchors, confs = postprocess_predictions(confidences, reordered_frames)\n",
    "anchors = np.array(anchors)\n",
    "confs = np.stack(confs)\n",
    "# anchors, confs = postprocess_peaks_only(confidences, reordered_frames, height=0.5, distance=8, width=0)\n",
    "# confs[confs > 0.9] = 1\n",
    "postprocess_list = []\n",
    "# array index, frame confidences\n",
    "for idx, (f, cs) in enumerate(zip(anchors, confs)):\n",
    "    # class int and confidence per class\n",
    "    for i, c in enumerate(cs):\n",
    "        plot_preds = {}\n",
    "        plot_preds[\"frame\"] = f\n",
    "        plot_preds[\"type\"] = int2class(i)\n",
    "        plot_preds[\"confidence\"] = c\n",
    "        plot_preds[\"idx\"] = idx \n",
    "        postprocess_list.append(plot_preds)\n",
    "\n",
    "pp_df = pd.DataFrame(postprocess_list)\n",
    "\n",
    "# plot predicted anchors from postprocessing\n",
    "pp_in_plot = pp_df[(pp_df.frame < end_frame) & (pp_df.frame > start_frame)]\n",
    "for i, row in pp_in_plot.iterrows():\n",
    "    if row[\"type\"] != \"Background\":\n",
    "        ax.axvline(x=row[\"frame\"], color=palette[class2int(row[\"type\"])], ymax=row[\"confidence\"], linestyle=':')\n",
    "        idx = row[\"idx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_data[(plot_data[\"type\"] == \"Pass\") & (plot_data[\"confidence\"] > 0.5)][[\"frame\", \"confidence\"]])\n",
    "print(pp_in_plot[(pp_in_plot[\"type\"] == \"Pass\") & (pp_in_plot[\"confidence\"] > 0.5)].frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 29.97\n",
    "print(average_mAP(confs, anchors, gt_labels_ll, gt_anchors_ll, tolerances=[fps, 2*fps, 3*fps, 10*fps]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6bfefc7a39950bcdd742af1d8d7db7c97e184d8839e8870b13ce1c69afb51e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
