{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # root of repo\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import ipywidgets as widgets\n",
    "from collections import Counter, defaultdict\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from src.data import MultiModalHblDataset\n",
    "from src.utils import array2gif, draw_trajectory\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking frequencies of labels across matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False   \n",
    ")\n",
    "ctr = Counter()\n",
    "no_action = 0\n",
    "print(\"Dataset size:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, instance in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    label = instance[\"label\"]\n",
    "    if not label == {}:\n",
    "        ctr.update({f\"{label['Pass']}{label['Wurf']}\" : 1})\n",
    "    else:\n",
    "        no_action += 1\n",
    "\n",
    "class_combinations = pd.DataFrame()\n",
    "for (pass_cls, shot_cls), n in ctr.items():\n",
    "    class_combinations.loc[shot_cls, pass_cls] = n\n",
    "print(\"No action:\", no_action)\n",
    "class_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_combinations.sum().sum() + no_action == len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_combinations.to_csv(\"occurences_16_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "class2frame = defaultdict(list)\n",
    "valid_combs = ['A0', 'A1', 'B0', 'O0', 'C0', 'D0', 'X0', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8']\n",
    "\n",
    "for events in tqdm(dataset.event_dfs):\n",
    "    events[\"Wurf\"] = events.labels.apply(lambda x : x[\"Wurf\"])\n",
    "    events[\"Pass\"] = events.labels.apply(lambda x : x[\"Pass\"])\n",
    "    for k in valid_combs:\n",
    "        p, w = k\n",
    "        f = events[(events[\"Pass\"] == p) & (events[\"Wurf\"] == w)].index.tolist()\n",
    "        if f:\n",
    "            class2frame[k].append(f)\n",
    "\n",
    "with open(\"class2frame.pkl\", \"wb+\") as f:\n",
    "    pkl.dump(class2frame, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding info to meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 2\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True   \n",
    ")\n",
    "# [(k, v) for (k,v) in dataset_img.event_dfs[0].head(20)[\"labels\"].items()]\n",
    "# 12126 O0\n",
    "print(\"Match boundaries:\", dataset_img.index_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 109340\n",
    "pos_offset = 0 # positive values move positions \"into the past\"\n",
    "example = dataset_img.__getitem__(idx) #, frame_idx=idx, match_number=0)\n",
    "\n",
    "frames = np.transpose(example[\"frames\"], (3, 0, 1, 2))\n",
    "positions = example[\"positions\"]\n",
    "\n",
    "print(\"Frames and positions shape:\", frames.shape, positions.shape)\n",
    "print(\"Action label frame number:\", example[\"label_offset\"])\n",
    "print(\"Label:\", example[\"label\"])\n",
    "\n",
    "array2gif(frames, f\"../img/instance_{idx}_{sql}x{sr}.gif\", fps=10)\n",
    "fig = draw_trajectory(positions)\n",
    "# Mismatch Notes:\n",
    "# Game | positions offset\n",
    "# 0s   | 8 frames in the future\n",
    "# 1s   | 20 frames in the future, 109340 32x1\n",
    "# 2s   | mirrored, 16 frames in the past 204000 32x1\n",
    "# 3s   | looks good (319120 32x1 data)\n",
    "# 4s   | 16 frames in the future, see 426000 32x1\n",
    "# 5s   | mirrored, ok see 533450 32x1\n",
    "# 6s   | mirrored, ok, 641300 31x1\n",
    "# 7s   | 5 frames in the future, 745700 32x1\n",
    "# 8s   | mirrored, 47 frames in the future 854000 32x1\n",
    "# 9s   | 16 frames in the future 962400 32x1\n",
    "# 10s  | mirrored, 8 in the future 1071800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\"\n",
    "df = pd.read_csv(p, index_col=\"match_id\")\n",
    "\n",
    "vertical = [1, 2, 5, 6, 8, 10]\n",
    "horizontal = [1, 2, 5, 6, 8, 10]\n",
    "for idx, (i, _) in enumerate(df.iterrows()):\n",
    "    df.loc[i, \"mirror_vertical\"] = idx in vertical\n",
    "    df.loc[i, \"mirror_horizontal\"] = idx in horizontal\n",
    "\n",
    "df.to_csv(p)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting positions and frames per halftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 2\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True   \n",
    ")\n",
    "# [(k, v) for (k,v) in dataset_img.event_dfs[0].head(20)[\"labels\"].items()]\n",
    "# 12126 O0\n",
    "print(\"Match boundaries:\", dataset_img.index_tracker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match bounds [0, 106194, 212206, 318712, 425410, 531648, 640606, 745140, 853159, 960038, 1065755, 1172197]\n",
    "events = dataset_img.event_dfs\n",
    "\n",
    "for i,event_df in enumerate(events):\n",
    "    print(i, \"---\")\n",
    "    print(\"First frame\", dataset_img.idx_to_frame_number[i][0])\n",
    "    print(\"First action\", event_df.index[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging idx -> Frame index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 4\n",
    "hql = sql // 2\n",
    "rate = 2\n",
    "sr = sql * rate\n",
    "hr = hql * rate\n",
    "kernel = np.ones(sr)\n",
    "\n",
    "availables = [True, True, True, True, True, True, True, True, True, True, True, True, True, False, False]\n",
    "pos = np.arange(len(availables))\n",
    "\n",
    "cv = np.convolve(availables, kernel)\n",
    "print(f\"{cv}\")\n",
    "idxs = np.where(cv == sr)[0] - (sr - 1) # subtract filter length - 1\n",
    "print(\"idx for valid sequences:\", idxs)\n",
    "\n",
    "q_idx = 0\n",
    "f_idx = idxs[q_idx] + hr\n",
    "sequence = pos[f_idx - hr : f_idx + hr : rate]\n",
    "print(f\"Idx for sequence {q_idx}: {sequence}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 2\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True\n",
    ")\n",
    "\n",
    "with open(\"class2frame.pkl\", \"rb\") as f:\n",
    "    class2frame = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../img/classes\", exist_ok=True)\n",
    "n_per_class = 3\n",
    "for cls, frame_lists in class2frame.items():\n",
    "    match_id = 0\n",
    "    frame_id = 0\n",
    "    n = 0\n",
    "    for i, fl in enumerate(frame_lists):\n",
    "        if n == n_per_class:\n",
    "            break\n",
    "        if fl:\n",
    "            match_id = i\n",
    "            try:\n",
    "                frame_id = fl[(len(fl) // 2) + n] # dont take first pass of the game\n",
    "            except:\n",
    "                continue\n",
    "            example = dataset_img.__getitem__(0, frame_idx=frame_id, match_number=match_id)\n",
    "            frames = example[\"frames\"].transpose(1, 0, 2, 3)\n",
    "            gifname = f\"../img/classes/{cls}_{n}_{match_id}x{frame_id}.gif\"\n",
    "            array2gif(frames, gifname, fps=10)\n",
    "\n",
    "            positions = example[\"positions\"]\n",
    "            fig = draw_trajectory(positions)\n",
    "            figname = f\"../img/classes/{cls}_{n}_{match_id}x{frame_id}.png\"\n",
    "            fig.savefig(figname)\n",
    "            print(figname)\n",
    "            print(gifname)\n",
    "\n",
    "            n+= 1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 1\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True\n",
    ")\n",
    "print(len(dataset_img))\n",
    "n = 0\n",
    "means = np.zeros((len(dataset_img) + sql, 3))\n",
    "stds = np.zeros((len(dataset_img) + sql, 3))\n",
    "\n",
    "for i in tqdm(range(0, len(dataset_img), sql)):\n",
    "    frames = torch.tensor(dataset_img[i][\"frames\"]) / 255\n",
    "\n",
    "    for j, frame in enumerate(frames):\n",
    "        mean, std = frame.mean([1,2]), frame.std([1,2])\n",
    "        means[i+j] = mean\n",
    "        stds[i+j] = std\n",
    "\n",
    "        n+=1\n",
    "print(n)\n",
    "print(means.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"means.npy\", means)\n",
    "np.save(\"std.npy\", stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.mean(0), stds.mean(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6bfefc7a39950bcdd742af1d8d7db7c97e184d8839e8870b13ce1c69afb51e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
