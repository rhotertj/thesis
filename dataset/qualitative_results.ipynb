{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.manifold import TSNE\n",
    "from omegaconf import OmegaConf as omcon\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchmetrics.classification import MulticlassAveragePrecision\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # root of repo\n",
    "sys.path.append(\"/nfs/home/rhotertj/Code/thesis/src\")\n",
    "import src.multimodal_transforms as mmt\n",
    "from src.lit_models import LitModel, weighted_cross_entropy, unweighted_cross_entropy, twin_head_loss, Cache\n",
    "from src.video_models import make_kinetics_mvit\n",
    "from src.graph_models import GAT, PositionTransformer, GIN\n",
    "from src.multimodal_models import MultiModalModel\n",
    "from src.lit_data import LitMultiModalHblDataset, LitResampledHblDataset, collate_function_builder\n",
    "from src.data import LabelDecoder\n",
    "from src.utils import get_proportions_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = Path(\"/nfs/home/rhotertj/Code/thesis/experiments/input_format/posiformer_indicator_shuffle_long\")\n",
    "# ckpt_dir = Path(\"/nfs/home/rhotertj/Code/thesis/experiments/architecture/mvit_twin\")\n",
    "\n",
    "\n",
    "\n",
    "ckpt_file = [f for f in os.listdir(ckpt_dir) if f.endswith(\".ckpt\")][-1]\n",
    "print(\"Loading\", ckpt_file)\n",
    "config = omcon.load(ckpt_dir / \"config.yaml\")\n",
    "cache = Cache()\n",
    "cache.load(ckpt_dir / \"test_results.pkl\")\n",
    "\n",
    "# remove pretrained model weights, they are overwritten anyways by lightning checkpoint\n",
    "if config.model.name == \"MultiModalModel\":\n",
    "    config.model.params.video_model_ckpt = \"\"\n",
    "    config.model.params.graph_model_ckpt = \"\"\n",
    "\n",
    "loss_func = eval(config.loss_func)\n",
    "label_decoder = LabelDecoder(config.num_classes)\n",
    "config.data.params.batch_size = 1\n",
    "config.data.params.load_frames = True\n",
    "\n",
    "lit_dataset = eval(config.data.name)(**config.data.params, label_mapping=label_decoder)\n",
    "lit_dataset.setup(\"test\")\n",
    "val_loader = lit_dataset.test_dataloader()\n",
    "dataset = lit_dataset.data_test\n",
    "\n",
    "base_path = Path(\".\") / \"analysis\" / ckpt_dir.name\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "model = eval(config.model.name)(**config.model.params,  num_classes=config.num_classes, batch_size=config.data.params.batch_size)\n",
    "print(config.model.name)\n",
    "lit_model = LitModel.load_from_checkpoint(\n",
    "    ckpt_dir / ckpt_file,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    loss_func=loss_func,\n",
    "    model=model,\n",
    "    label_mapping=label_decoder,\n",
    "    experiment_dir=base_path\n",
    ")\n",
    "lit_model = lit_model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU!\")\n",
    "    lit_model.cuda()\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run prediction on validation data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res_name = base_path / \"val_results.pkl\"\n",
    "if not os.path.exists(val_res_name):\n",
    "\n",
    "    val_results = [] # list of dicts with all info but frames, we can load them later via query idx!\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    for instance in tqdm(val_loader):\n",
    "        if \"frames\" in instance:\n",
    "            instance[\"frames\"] = instance[\"frames\"].to(device)\n",
    "        instance[\"positions\"] = instance[\"positions\"].to(device)\n",
    "        pred = lit_model.forward(instance)\n",
    "        if isinstance(pred, tuple):\n",
    "            pred, pred_offset = pred\n",
    "            pred = pred.detach().cpu()\n",
    "            pred_offset = pred_offset.detach().cpu()\n",
    "            loss = loss_func(pred, pred_offset, instance[\"label\"], instance[\"label_offset\"])\n",
    "        else:\n",
    "            pred = pred.detach().cpu()\n",
    "            loss = loss_func(pred, instance[\"label\"], instance[\"label_offset\"])\n",
    "        res = {\n",
    "            \"query_idx\" : instance[\"query_idx\"].item(),\n",
    "            \"frame_idx\" : instance[\"frame_idx\"].item(),\n",
    "            \"match_number\" : instance[\"match_number\"].item(),\n",
    "            \"label\" : instance[\"label\"].item(),\n",
    "            \"label_offset\" : instance[\"label_offset\"].item(),\n",
    "            \"label_idx\" : instance[\"label_offset\"].item(),\n",
    "            \"prediction\" : pred.detach().cpu().numpy().argmax(-1),\n",
    "            \"confidences\" : pred.detach().cpu().numpy(),\n",
    "            \"loss\" : loss.item()\n",
    "        }\n",
    "        val_results.append(res)\n",
    "\n",
    "    with open(val_res_name, \"wb+\") as f:\n",
    "        pkl.dump(val_results, f)\n",
    "\n",
    "else:\n",
    "    with open(val_res_name, \"rb\") as f:\n",
    "        val_results = pkl.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = cache.data[\"ground_truths\"]\n",
    "preds = cache.data[\"predictions\"]\n",
    "confs = torch.stack(cache.data[\"confidences\"])\n",
    "\n",
    "f1 = f1_score(gt, preds, average=None)\n",
    "print(\"f1:\", f1)\n",
    "ap_metric = MulticlassAveragePrecision(num_classes=3, average=\"none\")\n",
    "gt_tensor = torch.tensor(gt)\n",
    "print(\"AP:\", ap_metric(confs, gt_tensor))\n",
    "\n",
    "confmat = confusion_matrix(gt, preds).astype(np.float64)\n",
    "confmat_frac = np.zeros_like(confmat)\n",
    "_, counts = np.unique(preds, return_counts=True)\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=300)\n",
    "for i in range(3):\n",
    "    confmat_frac[i] = (confmat[i, :] / np.sum(confmat[i, :]))\n",
    "\n",
    "# initialize using the raw 2D confusion matrix \n",
    "# and output labels (in our case, it's 0 and 1)\n",
    "confmat = confmat.astype(np.int64)\n",
    "labels = [\"Background\", \"Pass\", \"Shot\"]\n",
    "sns.heatmap(confmat_frac, annot=confmat, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels, cbar=True, square=True, ax=ax)\n",
    "ax.set(ylabel=\"Ground Truth\", xlabel=\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb import util\n",
    "from wandb.plots.utils import test_missing, test_types\n",
    "import wandb\n",
    "\n",
    "\n",
    "def pr_curve(\n",
    "    y_true=None,\n",
    "    y_probas=None,\n",
    "    labels=None,\n",
    "    classes_to_plot=None,\n",
    "    interp_size=21,\n",
    "):\n",
    "    \"\"\"Compute the tradeoff between precision and recall for different thresholds.\n",
    "\n",
    "    A high area under the curve represents both high recall and high precision, where\n",
    "    high precision relates to a low false positive rate, and high recall relates to a\n",
    "    low false negative rate. High scores for both show that the classifier is returning\n",
    "    accurate results (high precision), and returning a majority of all positive results\n",
    "    (high recall). PR curve is useful when the classes are very imbalanced.\n",
    "\n",
    "    Arguments:\n",
    "        y_true (arr): true sparse labels y_probas (arr): Target scores, can either be\n",
    "            probability estimates, confidence values, or non-thresholded measure of\n",
    "            decisions. shape: (*y_true.shape, num_classes)\n",
    "        labels (list): Named labels for target variable (y). Makes plots easier to read\n",
    "            by replacing target values with corresponding index. For example labels =\n",
    "            ['dog', 'cat', 'owl'] all 0s are replaced by 'dog', 1s by 'cat'.\n",
    "        classes_to_plot (list): unique values of y_true to include in the plot\n",
    "        interp_size (int): the recall values will be fixed to `interp_size` points\n",
    "            uniform on [0, 1] and the precision will be interpolated for these recall\n",
    "            values.\n",
    "\n",
    "    Returns:\n",
    "        Nothing. To see plots, go to your W&B run page then expand the 'media' tab under\n",
    "        'auto visualizations'.\n",
    "\n",
    "    Example:\n",
    "        ```\n",
    "        wandb.log({\"pr-curve\": wandb.plot.pr_curve(y_true, y_probas, labels)})\n",
    "        ```\n",
    "    \"\"\"\n",
    "    np = util.get_module(\n",
    "        \"numpy\",\n",
    "        required=\"roc requires the numpy library, install with `pip install numpy`\",\n",
    "    )\n",
    "    pd = util.get_module(\n",
    "        \"pandas\",\n",
    "        required=\"roc requires the pandas library, install with `pip install pandas`\",\n",
    "    )\n",
    "    sklearn_metrics = util.get_module(\n",
    "        \"sklearn.metrics\",\n",
    "        \"roc requires the scikit library, install with `pip install scikit-learn`\",\n",
    "    )\n",
    "    sklearn_utils = util.get_module(\n",
    "        \"sklearn.utils\",\n",
    "        \"roc requires the scikit library, install with `pip install scikit-learn`\",\n",
    "    )\n",
    "\n",
    "    def _step(x):\n",
    "        y = np.array(x)\n",
    "        for i in range(1, len(y)):\n",
    "            y[i] = max(y[i], y[i - 1])\n",
    "        return y\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "    if not test_missing(y_true=y_true, y_probas=y_probas):\n",
    "        return\n",
    "    if not test_types(y_true=y_true, y_probas=y_probas):\n",
    "        return\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    if classes_to_plot is None:\n",
    "        classes_to_plot = classes\n",
    "\n",
    "    precision = dict()\n",
    "    interp_recall = np.linspace(0, 1, interp_size)[::-1]\n",
    "    indices_to_plot = np.where(np.isin(classes, classes_to_plot))[0]\n",
    "    for i in indices_to_plot:\n",
    "        if labels is not None and (\n",
    "            isinstance(classes[i], int) or isinstance(classes[0], np.integer)\n",
    "        ):\n",
    "            class_label = labels[classes[i]]\n",
    "        else:\n",
    "            class_label = classes[i]\n",
    "\n",
    "        cur_precision, cur_recall, _ = sklearn_metrics.precision_recall_curve(\n",
    "            y_true, y_probas[:, i], pos_label=classes[i]\n",
    "        )\n",
    "        # smooth the precision (monotonically increasing)\n",
    "        cur_precision = _step(cur_precision)\n",
    "\n",
    "        # reverse order so that recall in ascending\n",
    "        cur_precision = cur_precision[::-1]\n",
    "        cur_recall = cur_recall[::-1]\n",
    "        indices = np.searchsorted(cur_recall, interp_recall, side=\"left\")\n",
    "        precision[class_label] = cur_precision[indices]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"class\": np.hstack([[k] * len(v) for k, v in precision.items()]),\n",
    "            \"precision\": np.hstack(list(precision.values())),\n",
    "            \"recall\": np.tile(interp_recall, len(precision)),\n",
    "        }\n",
    "    )\n",
    "    df = df.round(3)\n",
    "\n",
    "    if len(df) > wandb.Table.MAX_ROWS:\n",
    "        wandb.termwarn(\n",
    "            \"wandb uses only %d data points to create the plots.\" % wandb.Table.MAX_ROWS\n",
    "        )\n",
    "        # different sampling could be applied, possibly to ensure endpoints are kept\n",
    "        df = sklearn_utils.resample(\n",
    "            df,\n",
    "            replace=False,\n",
    "            n_samples=wandb.Table.MAX_ROWS,\n",
    "            random_state=42,\n",
    "            stratify=df[\"class\"],\n",
    "        ).sort_values([\"precision\", \"recall\", \"class\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = pr_curve(gt, confs, labels=[\"Background\", \"Pass\", \"Shot\"])\n",
    "fig, ax = plt.subplots(figsize=(10,6), dpi=300)\n",
    "\n",
    "ax = sns.lineplot(data=pr_df, x=\"recall\", y=\"precision\", hue=\"class\", markers=True, dashes=False, palette=\"Set2\", linestyle=\"--\", ax=ax)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution over offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cache.data)\n",
    "df[\"correct\"] = False\n",
    "df.loc[df[\"ground_truths\"] == df[\"predictions\"], \"correct\"] = True\n",
    "df_nobg = df[df[\"ground_truths\"] != 0]\n",
    "dataset.load_frames = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(20,8))\n",
    "sns_plot = sns.countplot(data=df_nobg, x=\"label_offsets\", hue=\"correct\", width=0.8, ax=ax)\n",
    "sns_plot.set_xticklabels(list(np.arange(0,16,0.5)))\n",
    "sns_plot.set_xlabel(\"Position of annotated frame in window\")\n",
    "sns_plot.set_ylabel(\"Count\")\n",
    "legend = sns_plot.get_legend()\n",
    "legend.set_title(\"Correct Prediction\")\n",
    "sns_plot.figure.savefig(base_path / \"offsets.png\",dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renew_figure():\n",
    "    plt.clf()\n",
    "    fig, axis = plt.subplots(2, n, figsize=(16,8))\n",
    "    return fig, axis\n",
    "\n",
    "def animate_samples(dataset, df, n):\n",
    "    fig, axis = renew_figure()\n",
    "    sample_frames = []\n",
    "    sample_positions = []\n",
    "    query_idx = []\n",
    "    for i, sample in df.sample(n).iterrows():\n",
    "        idx = i\n",
    "        frames = dataset[idx][\"frames\"].numpy() # cthw\n",
    "        positions = dataset[idx][\"positions\"].as_TNC(normalize=False)\n",
    "        sample_frames.append(frames)\n",
    "        sample_positions.append(positions)\n",
    "        query_idx.append(idx)\n",
    "    # list of 16 entries, each a list of n frames\n",
    "    sample_frames = np.stack(sample_frames) # ncthw\n",
    "    sample_frames = np.einsum(\"ncthw->nthwc\", sample_frames)\n",
    "\n",
    "    images = []\n",
    "    for t in range(sample_frames.shape[1]):\n",
    "        images_at_timestep = []\n",
    "        for i in range(sample_frames.shape[0]):\n",
    "            # video\n",
    "            im = axis[0, i].imshow(sample_frames[i, t])\n",
    "            axis[0, i].tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "            images_at_timestep.append(im)\n",
    "            # positions\n",
    "            colors = [\"red\", \"green\", \"blue\"]\n",
    "            scatterplot = axis[1, i].scatter(\n",
    "                x=sample_positions[i][t, :, 1],\n",
    "                y=sample_positions[i][t, :, 2],\n",
    "                c=[colors[int(m)] for m in sample_positions[i][t, :, 0]]\n",
    "            )\n",
    "            \n",
    "            axis[1, i].tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "            axis[0, i].set_title(f\"label: {sample['ground_truths']}, pred: {sample['predictions']}, {query_idx[i]}\", fontsize='small', loc='left')\n",
    "            images_at_timestep.append(scatterplot)\n",
    "\n",
    "        images.append(images_at_timestep)\n",
    "        \n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, images, interval=50, blit=False, repeat_delay=1000)\n",
    "    return ani\n",
    "\n",
    "for c in label_decoder.get_classnames():\n",
    "    label_int = label_decoder.get_classnames().index(c)\n",
    "    n = 5\n",
    "\n",
    "    tp = df[(df[\"ground_truths\"] == label_int) & (df[\"predictions\"] == label_int)]\n",
    "    fp = df[(df[\"ground_truths\"] != label_int) & (df[\"predictions\"] == label_int)]\n",
    "    fn = df[(df[\"ground_truths\"] == label_int) & (df[\"predictions\"] != label_int)]\n",
    "\n",
    "\n",
    "    animate_samples(dataset, tp, 5).save(base_path / f\"{c}_tp.gif\", fps=10)\n",
    "    animate_samples(dataset, fp, 5).save(base_path / f\"{c}_fp.gif\", fps=10)\n",
    "    animate_samples(dataset, fn, 5).save(base_path / f\"{c}_fn.gif\", fps=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-k loss predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in label_decoder.get_classnames():\n",
    "    label_int = label_decoder.get_classnames().index(c)\n",
    "    n = 5\n",
    "    c_df = df[df[\"ground_truths\"] == label_int]\n",
    "    topk = c_df.sort_values(by=\"loss\", ascending=True).head(n)\n",
    "    worstk = c_df.sort_values(by=\"loss\", ascending=False).head(n)\n",
    "    \n",
    "\n",
    "    animate_samples(dataset, topk, n).save(base_path / f\"{c}_topk.gif\", fps=10)\n",
    "    animate_samples(dataset, worstk, n).save(base_path / f\"{c}_worstk.gif\", fps=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "representations = []\n",
    "labels = []\n",
    "preds = []\n",
    "indices = np.random.randint(low=0, high=len(dataset), size=n)\n",
    "# maybe do this with multimodal model and use the representations from there?\n",
    "for i, instance in enumerate(tqdm(val_loader)):\n",
    "    if i == n:\n",
    "        break\n",
    "    lit_model.model.head_type = \"pool\"\n",
    "    r = lit_model.model(instance[\"positions\"])\n",
    "    lit_model.model.head_type = \"classify\"\n",
    "    pred = lit_model.model(instance[\"positions\"])\n",
    "    representations.append(r)\n",
    "    labels.append(label_decoder.class_names[instance[\"label\"].item()])\n",
    "    preds.append(label_decoder.class_names[pred.argmax().item()])\n",
    "\n",
    "representations = torch.stack(representations).squeeze(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(representations.shape)\n",
    "tsne = TSNE()\n",
    "embedded_representations = tsne.fit_transform(representations)\n",
    "print(embedded_representations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame({\n",
    "    \"x\" : embedded_representations[:,0],\n",
    "    \"y\" : embedded_representations[:,1],\n",
    "    \"label\" : labels,\n",
    "    \"prediction\" : preds\n",
    "}) \n",
    "# TODO: ground truth color, prediction as shape\n",
    "sns.scatterplot(data=tsne_df, x=\"x\", y=\"y\", style=\"prediction\", hue=\"label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
