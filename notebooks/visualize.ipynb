{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # root of repo\n",
    "sys.path.append(\"../src/\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import Counter, defaultdict\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from src.data.datasets import MultiModalHblDataset, ResampledHblDataset\n",
    "from src.data.labels import LabelDecoder\n",
    "from src.utils import array2gif, draw_trajectory\n",
    "from src.metrics import average_mAP, nms_peaks\n",
    "import torchvision\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision.transforms as t\n",
    "import multimodal_transforms as mmt\n",
    "import pytorchvideo.transforms as ptvt\n",
    "from lit_data import collate_function_builder\n",
    "from scripts.resample_data import create_dataframe_from_dataset\n",
    "from utils import * # debug import\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    # \"font.sans-serif\": \"Helvetica\",\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot dataset stats and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_test.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/False/overlap/False/sql_sr/16x2/mode/matches/upsampled/False/meta30_train.jsonl\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False,\n",
    "    label_mapping=LabelDecoder(3)\n",
    ")\n",
    "print(len(data.event_dfs))\n",
    "dataset = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False,\n",
    "    overlap=False\n",
    ")\n",
    "# data = create_dataframe_from_dataset(dataset)\n",
    "ld = LabelDecoder(3)\n",
    "classes = ld.get_classnames()\n",
    "\n",
    "data.idx_to_frame_number.label = data.idx_to_frame_number.label.apply(lambda x: classes[ld(x)])\n",
    "cmap = list(sns.color_palette(\"Set2\", as_cmap=True).colors)\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "sns.countplot(data=data.idx_to_frame_number, x=\"match_number\", hue=\"label\", palette=cmap)\n",
    "# sns.countplot(data=data, x=\"match_number\", hue=\"label\", palette=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "counts = data.value_counts([\"label\"])\n",
    "print(counts)\n",
    "plt.pie(counts, colors=cmap, labels=classes, autopct='%1.1f%%')\n",
    "plt.legend()\n",
    "plt.title(\"Class distribution (train split)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_idx = []\n",
    "frame_offset = 10**7\n",
    "for i, event_df in enumerate(dataset.event_dfs):\n",
    "    idx = event_df.index.to_numpy()\n",
    "    actions = idx + frame_offset * i\n",
    "    action_idx.append(actions)\n",
    "\n",
    "actions = np.concatenate(action_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_distances = np.diff(actions) / 29.97\n",
    "bins = list(range(0,20))\n",
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "\n",
    "_ = plt.hist(action_distances, bins=bins, histtype='bar', align='mid', color=cmap[4])\n",
    "plt.xticks(ticks=bins, labels=bins)\n",
    "plt.xlabel(\"seconds\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.title(\"Temporal distance between two actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_frames = True\n",
    "data.transforms = t.Compose([\n",
    "    mmt.FrameSequenceToTensor(),\n",
    "    mmt.Resize(size=(224,224))\n",
    "    ])\n",
    "fig, axes = plt.subplots(1,3, figsize=(14,7))\n",
    "for i, idx in enumerate([1790, 6000, 12900]):\n",
    "    frames = data[idx][\"frames\"]\n",
    "    frames = frames.mul(255).to(torch.uint8).numpy()\n",
    "    frames = np.einsum(\"cthw->thwc\", frames)\n",
    "    axes[i].tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "    axes[i].imshow(frames[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, figsize=(18, 7))\n",
    "draw_trajectory(data[2380][\"positions\"], ax=axes[0])\n",
    "draw_trajectory(data[7039][\"positions\"], ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = t.Compose([\n",
    "    mmt.FrameSequenceToTensor(),\n",
    "    mmt.Resize(size=(224,224))\n",
    "    ])\n",
    "dataset = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_test.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/False/overlap/True/sql_sr/16x2/mode/matches/upsampled/False/meta30_test.jsonl\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=True,\n",
    "    transforms=trf,\n",
    "    label_mapping=LabelDecoder(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14,4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "idx = 124292\n",
    "frames = dataset[idx][\"frames\"]\n",
    "frames = frames.mul(255).to(torch.uint8).numpy()\n",
    "frames = np.einsum(\"cthw->thwc\", frames)\n",
    "for i in [0,1]:\n",
    "    axes[i].tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "axes[0].imshow(frames[10])\n",
    "draw_trajectory(dataset[idx][\"positions\"], ax=axes[1], colors=[\"green\", \"red\", \"blue\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging idx -> Frame index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 4\n",
    "hql = sql // 2\n",
    "rate = 2\n",
    "sr = sql * rate\n",
    "hr = hql * rate\n",
    "kernel = np.ones(sr)\n",
    "\n",
    "availables = [True, True, True, True, True, True, True, True, True, True, True, True, True, False, False]\n",
    "pos = np.arange(len(availables))\n",
    "\n",
    "cv = np.convolve(availables, kernel)\n",
    "print(f\"{cv}\")\n",
    "idxs = np.where(cv == sr)[0] - (sr - 1) # subtract filter length - 1\n",
    "print(\"idx for valid sequences:\", idxs)\n",
    "\n",
    "q_idx = 0\n",
    "f_idx = idxs[q_idx] + hr\n",
    "sequence = pos[f_idx - hr : f_idx + hr : rate]\n",
    "print(f\"Idx for sequence {q_idx}: {sequence}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_valid.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/meta30_val.jsonl\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=True,\n",
    "    label_mapping=LabelDecoder(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../img/classes\", exist_ok=True)\n",
    "n_per_class = 3\n",
    "shots = list(range(0, 9))\n",
    "passes = ['A', 'B', 'C', 'D', 'E', 'X', 'O']\n",
    "df = dataset.idx_to_frame_number\n",
    "for s,p in itertools.product(shots, passes):\n",
    "    events = df[(df['shot'] == s) & (df['pass'] == p)]\n",
    "    if len(events) > 0:\n",
    "        events = events.sample(n_per_class)\n",
    "        for i, (idx, event) in enumerate(events.iterrows()):\n",
    "            instance = dataset.__getitem__(idx)\n",
    "            fname = f\"../img/classes/{s}_{p}_{i}\"\n",
    "            array2gif(instance[\"frames\"], fname + \".gif\", 10)\n",
    "            f = draw_trajectory(instance[\"positions\"])\n",
    "            plt.savefig(fname + \".png\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 16\n",
    "sr = 1\n",
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=sql,\n",
    "    sampling_rate=sr,\n",
    "    load_frames=True\n",
    ")\n",
    "print(len(dataset_img))\n",
    "n = 0\n",
    "means = np.zeros((len(dataset_img) + sql, 3))\n",
    "stds = np.zeros((len(dataset_img) + sql, 3))\n",
    "\n",
    "for i in tqdm(range(0, len(dataset_img), sql)):\n",
    "    frames = torch.tensor(dataset_img[i][\"frames\"]) / 255\n",
    "\n",
    "    for j, frame in enumerate(frames):\n",
    "        mean, std = frame.mean([1,2]), frame.std([1,2])\n",
    "        means[i+j] = mean\n",
    "        stds[i+j] = std\n",
    "\n",
    "        n+=1\n",
    "print(n)\n",
    "print(means.shape)\n",
    "# Maybe we want to calculate this per match instead of over the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"means.npy\", means)\n",
    "np.save(\"std.npy\", stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.mean(0), stds.mean(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta3d.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = dataset_img[11345]\n",
    "draw_trajectory(instance[\"positions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poscon = instance[\"positions\"].mirror_again(horizontal=True, vertical=False)\n",
    "draw_trajectory(poscon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transforms and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms_jitter = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.ColorJitter(brightness=0.2, hue=.2, contrast=0.2, saturation=0.2),\n",
    "            mmt.ChannelFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            ])\n",
    "\n",
    "transforms_randaugment = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            #ptvt.RandAugment(num_layers=3, prob=0.5, magnitude=5),\n",
    "            mmt.ChannelFirst(),\n",
    "            ])\n",
    "\n",
    "transforms_translate = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            mmt.Translate()\n",
    "    ])\n",
    "\n",
    "transforms_raw = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "    ])\n",
    "\n",
    "transforms_full = t.Compose([\n",
    "            mmt.FrameSequenceToTensor(),\n",
    "            mmt.RandomHorizontalFlipVideo(p=0.5),\n",
    "            mmt.TimeFirst(),\n",
    "            mmt.ColorJitter(brightness=0.2, hue=.2, contrast=0.2, saturation=0.2),\n",
    "            #ptvt.RandAugment(num_layers=3, prob=0.5, magnitude=5),\n",
    "            mmt.ChannelFirst(),\n",
    "            mmt.Resize(size=(224,224)),\n",
    "            ])\n",
    "dataset_img = ResampledHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30_train.csv\",\n",
    "    idx_to_frame=\"/nfs/home/rhotertj/datasets/hbl/resampled/balanced/True/overlap/True/sql_sr/16x2/mode/matches/upsampled/True/meta30_train.jsonl\",\n",
    "    label_mapping=LabelDecoder(3),\n",
    "    load_frames=True,\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    transforms=transforms_raw\n",
    ")\n",
    "\n",
    "collate_mixvideo = collate_function_builder(epsilon=7, load_frames=True, mix_video=ptvt.MixVideo(num_classes=3, cutmix_alpha=0.8, cutmix_prob=0))\n",
    "collate_fn = collate_function_builder(epsilon=7, load_frames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_instances = []\n",
    "jitter_instances = []\n",
    "randaug_instances = []\n",
    "combined_instances = []\n",
    "translate_instances = []\n",
    "idxs = [13456,23574,98533,64378,22546,324567,243343,9632] #random\n",
    "for i in range(8):\n",
    "    dataset_img.transforms = transforms_raw\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    raw_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_translate\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    translate_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_jitter\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    jitter_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_randaugment\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    randaug_instances.append(instance)\n",
    "\n",
    "    dataset_img.transforms = transforms_full\n",
    "    instance = dataset_img[idxs[i]]\n",
    "    combined_instances.append(instance)\n",
    "dataset_img.transforms = transforms_raw\n",
    "\n",
    "raw_batch = collate_fn(raw_instances)\n",
    "mix_batch = collate_mixvideo(raw_instances)\n",
    "jitter_batch = collate_fn(jitter_instances)\n",
    "translate_batch = collate_fn(translate_instances)\n",
    "combined_batch = collate_mixvideo(combined_instances)\n",
    "\n",
    "raw_pos = None\n",
    "for i in range(8):\n",
    "    for name, batch in zip([\"raw\", \"mixvideo\", \"jitter\", \"translate\", \"combined\"], [raw_batch, mix_batch, jitter_batch, translate_batch, combined_batch]):\n",
    "        frames = batch[\"frames\"][i].mul(255).to(torch.uint8).numpy()\n",
    "        #array2gif(frames, f\"../img/transforms/{name}_transforms_{i}.gif\", 10)\n",
    "        if name == \"raw\":\n",
    "            raw_pos = batch[\"positions\"]\n",
    "        if name in (\"translate\", \"raw\"):\n",
    "            q_idx = batch[\"query_idx\"][i].item()\n",
    "            pos = dataset_img[q_idx][\"positions\"]\n",
    "            #fig = draw_trajectory(pos)\n",
    "            #plt.savefig(f\"../img/transforms/{name}_transforms_positions_{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6), dpi=300)\n",
    "for i, (name, batch) in enumerate(zip([\"Original\", \"MixVideo\", \"Full\"], [raw_batch, mix_batch, combined_batch])):\n",
    "    frames = np.einsum(\"chw->hwc\" , batch[\"frames\"][4].mul(255).to(torch.uint8).numpy()[:, 0,])\n",
    "    axes[i].tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "    axes[i].imshow(frames)\n",
    "    axes[i].set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = raw_batch[\"frames\"][1]\n",
    "print(instance.shape)\n",
    "instance = np.einsum(\"cthw->thwc\" , instance.mul(255).to(torch.uint8).numpy())\n",
    "for i, img in enumerate(instance):\n",
    "    print(img.shape)\n",
    "    fig, axes = plt.subplots(1, 1, dpi=300)\n",
    "    axes.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False\n",
    "            )\n",
    "    axes.imshow(img)\n",
    "    plt.savefig(f\"../img/frames/frame_{i}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_img = MultiModalHblDataset(\n",
    "    meta_path=\"/nfs/home/rhotertj/datasets/hbl/meta30.csv\",\n",
    "    seq_len=16,\n",
    "    sampling_rate=2,\n",
    "    load_frames=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_match = 2\n",
    "mult = 100\n",
    "for i, border in tqdm(enumerate(dataset_img.index_tracker[:-1])):\n",
    "    for j in range(n_per_match):\n",
    "        instance = dataset_img[border + (j+2)*mult]\n",
    "        mn = dataset_img.meta_df.iloc[instance[\"match_number\"]][\"match_id\"].split(\":\")[-1]\n",
    "        os.makedirs(f\"/nfs/home/rhotertj/Code/thesis/img/matches/{mn}\",exist_ok=True)\n",
    "        fname = f\"../img/matches/{mn}/{(j+8)*mult}\"\n",
    "        array2gif(instance[\"frames\"], fname + \".gif\", 10)\n",
    "        f = draw_trajectory(instance[\"positions\"])\n",
    "        plt.savefig(fname + \".png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing average MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res_name = \"/nfs/home/rhotertj/Code/thesis/experiments/input_format/posiformer_indicator_shuffle_long/val_results.pkl\"\n",
    "# val_res_name = \"/nfs/home/rhotertj/Code/thesis/dataset/analysis/copper-bush-8/val_results.pkl\"\n",
    "with open(val_res_name, \"rb\") as f:\n",
    "    val_results = pkl.load(f)\n",
    "print(val_results.keys())\n",
    "df = pd.DataFrame(val_results)\n",
    "confidences = np.stack(df.confidences.to_numpy())\n",
    "frame_numbers = df.frame_idx.to_numpy()\n",
    "match_numbers = df.match_numbers.to_numpy()\n",
    "label_idx = df.action_idx.to_numpy()\n",
    "labels = df.ground_truths.to_numpy()\n",
    "label_offsets = df.label_offsets.to_numpy()\n",
    "\n",
    "# boost frame numbers per game\n",
    "max_frame_magnitude = len(str(frame_numbers.max()))\n",
    "frame_offset = 10**(max_frame_magnitude + 1)\n",
    "frame_numbers = frame_numbers + (frame_offset * match_numbers)\n",
    "\n",
    "correct_order = np.argsort(frame_numbers)\n",
    "reordered_frames = frame_numbers[correct_order]\n",
    "confidences = confidences[correct_order]\n",
    "\n",
    "# labelidx solution\n",
    "gt_labels_ll = []\n",
    "gt_anchors_ll = []\n",
    "offset_ll = []\n",
    "for i, l_idx in enumerate(label_idx):\n",
    "    if l_idx == -1:\n",
    "        continue\n",
    "    f = frame_offset * match_numbers[i] + l_idx\n",
    "    if f in gt_anchors_ll:\n",
    "        continue\n",
    "    l = labels[i]\n",
    "    gt_labels_ll.append(l)\n",
    "    gt_anchors_ll.append(f)\n",
    "    offset_ll.append(label_offsets[i])\n",
    "\n",
    "gt_anchors_ll = np.array(gt_anchors_ll)\n",
    "gt_labels_ll = np.array(gt_labels_ll)\n",
    "\n",
    "correct_order = np.argsort(gt_anchors_ll)\n",
    "gt_anchors_ll = gt_anchors_ll[correct_order]\n",
    "gt_labels_ll = gt_labels_ll[correct_order]\n",
    "gt_anchors = gt_anchors_ll\n",
    "gt_labels = gt_labels_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plots and helpers\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "lm = LabelDecoder(3)\n",
    "int2class = lambda i: lm.get_classnames()[i]\n",
    "class2int = lambda c: lm.get_classnames().index(c)\n",
    "\n",
    "# put predictions into \n",
    "pred_list = []\n",
    "for (f, cs) in zip(reordered_frames, confidences):\n",
    "    for i, c in enumerate(cs):\n",
    "        plot_preds = {}\n",
    "        plot_preds[\"frame\"] = f\n",
    "        plot_preds[\"type\"] = int2class(i)\n",
    "        plot_preds[\"confidence\"] = c\n",
    "        pred_list.append(plot_preds)\n",
    "\n",
    "pred_df = pd.DataFrame(pred_list)\n",
    "pred_df.sort_values(by=\"frame\", inplace=True)\n",
    "\n",
    "start_frame = 8000 # 5000 - 8000\n",
    "end_frame = 12000\n",
    "palette = sns.color_palette(\"husl\")\n",
    "class_palette = {c: color for c, color in zip(lm.get_classnames(), palette[:3])}\n",
    "plot_data = pred_df[(pred_df[\"frame\"] > start_frame) & (pred_df[\"frame\"] < end_frame)]\n",
    "sns.scatterplot(data=plot_data, x=\"frame\", y=\"confidence\", hue=\"type\", palette=class_palette, ax=ax)\n",
    "\n",
    "# plot ground truth\n",
    "plotted_frames_in_gt = np.where((gt_anchors < end_frame) & (gt_anchors > start_frame))[0]\n",
    "for c, f in zip(gt_labels[plotted_frames_in_gt], gt_anchors[plotted_frames_in_gt]):\n",
    "    if c != 0: # fix div by 2 == 0 bug later\n",
    "        ax.axvline(x=f, color=palette[c], linestyle=\"-\")\n",
    "        pass\n",
    "\n",
    "# do post-processing\n",
    "\n",
    "# anchors, confs = postprocess_predictions_nb(confidences, reordered_frames)\n",
    "anchors, confs = nms_peaks(confidences, reordered_frames, height=0.6, distance=24, width=16)\n",
    "anchors = np.array(anchors)\n",
    "confs = np.stack(confs)\n",
    "# confs[confs > 0.9] = 1\n",
    "postprocess_list = []\n",
    "# array index, frame confidences\n",
    "for idx, (f, cs) in enumerate(zip(anchors, confs)):\n",
    "    # class int and confidence per class\n",
    "    for i, c in enumerate(cs):\n",
    "        plot_preds = {}\n",
    "        plot_preds[\"frame\"] = f\n",
    "        plot_preds[\"type\"] = int2class(i)\n",
    "        plot_preds[\"confidence\"] = c\n",
    "        plot_preds[\"idx\"] = idx \n",
    "        postprocess_list.append(plot_preds)\n",
    "\n",
    "pp_df = pd.DataFrame(postprocess_list)\n",
    "\n",
    "# plot predicted anchors from postprocessing\n",
    "pp_in_plot = pp_df[(pp_df.frame < end_frame) & (pp_df.frame > start_frame)]\n",
    "for i, row in pp_in_plot.iterrows():\n",
    "    if row[\"type\"] != \"Background\":\n",
    "        ax.axvline(x=row[\"frame\"], color=palette[class2int(row[\"type\"])], ymax=row[\"confidence\"], linestyle=':')\n",
    "        idx = row[\"idx\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot wandb data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pass = pd.read_csv(\"/nfs/home/rhotertj/Code/thesis/dataset/csv/gnn_val_pass.csv\")\n",
    "acc_shot = pd.read_csv(\"/nfs/home/rhotertj/Code/thesis/dataset/csv/gnn_val_shot.csv\")\n",
    "acc_bg = pd.read_csv(\"/nfs/home/rhotertj/Code/thesis/dataset/csv/gnn_val_bg.csv\")\n",
    "acc_bg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pass.columns\n",
    "pass_list = []\n",
    "for epoch in range(len(acc_pass)):\n",
    "    for model in [\"gin\", \"gat\", \"gcn_timestep\", \"gcn_sequence\"]:\n",
    "        print(epoch, model)\n",
    "        pass_accuracy = acc_pass.loc[epoch, f\"{model} - val/acc_Pass\"]\n",
    "        shot_accuracy = acc_shot.loc[epoch, f\"{model} - val/acc_Shot\"]\n",
    "        bg_accuracy = acc_bg.loc[epoch, f\"{model} - val/acc_Background\"]\n",
    "        pass_list.append(\n",
    "            {\"epoch\" : epoch, \"model\" : model, \"val_acc_pass\" : pass_accuracy, \"val_acc_shot\" : shot_accuracy, \"val_acc_background\" : bg_accuracy}\n",
    "        )\n",
    "print(pass_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pass_list)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20,5), dpi=300, sharey=True)\n",
    "sns.lineplot(df, x=\"epoch\", y=\"val_acc_background\", hue=\"model\", palette=\"Set2\", style=\"model\", ax=axes[0], markers=True)\n",
    "axes[0].get_legend().remove()\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].grid()\n",
    "axes[0].set_xticks(list(range(5)))\n",
    "axes[0].set_title('Background')\n",
    "\n",
    "\n",
    "sns.lineplot(df, x=\"epoch\", y=\"val_acc_pass\", hue=\"model\", palette=\"Set2\", style=\"model\", ax=axes[1], markers=True)\n",
    "axes[1].get_legend().remove()\n",
    "axes[1].set_ylabel(\"Accuracy (Pass)\")\n",
    "axes[1].grid()\n",
    "axes[1].set_xticks(list(range(5)))\n",
    "axes[1].yaxis.set_tick_params(labelleft=True)\n",
    "axes[1].set_title('Pass')\n",
    "\n",
    "\n",
    "sns.lineplot(df, x=\"epoch\", y=\"val_acc_shot\", hue=\"model\", palette=\"Set2\", style=\"model\", ax=axes[2], markers=True)\n",
    "axes[2].get_legend().remove()\n",
    "axes[2].set_ylabel(\"Accuracy (Shot)\")\n",
    "axes[2].grid()\n",
    "axes[2].set_xticks(list(range(5)))\n",
    "axes[2].yaxis.set_tick_params(labelleft=True)\n",
    "axes[2].set_title('Shot')\n",
    "\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "\n",
    "fig.legend(by_label.values(), [\"GIN\", \"GAT\", \"GCN (timestep)\", \"GCN (sequence)\"], loc=\"outside right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6bfefc7a39950bcdd742af1d8d7db7c97e184d8839e8870b13ce1c69afb51e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
